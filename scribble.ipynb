{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import gym\n",
    "import matplotlib.pyplot as plt\n",
    "from f110_gym.envs.base_classes import Integrator\n",
    "from collections import Counter,defaultdict\n",
    "# np.set_printoptions(s/uppress=True,precision=4)\n",
    "import random\n",
    "import os\n",
    "import pickle\n",
    "import pandas as pd\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def render_callback(env_renderer):\n",
    "    # custom extra drawing function\n",
    "\n",
    "    e = env_renderer\n",
    "\n",
    "    # update camera to follow car\n",
    "    x = e.cars[0].vertices[::2]\n",
    "    y = e.cars[0].vertices[1::2]\n",
    "    top, bottom, left, right = max(y), min(y), min(x), max(x)\n",
    "    e.score_label.x = left\n",
    "    e.score_label.y = top - 700\n",
    "    e.left = left - 800\n",
    "    e.right = right + 800\n",
    "    e.top = top + 800\n",
    "    e.bottom = bottom - 800"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "global map_path,map_ext, num_agents, network_size\n",
    "num_agents = 1\n",
    "network_size = 51\n",
    "# map_path = '/home/praneeth/f1tenth_gym_ros/f1tenth_racetracks/Austin/Austin_map'\n",
    "# map_path = '/home/praneeth/f1tenth_gym_ros/f1tenth_racetracks/Catalunya/Catalunya_map'\n",
    "# map_path = '/home/praneeth/f1tenth_gym_ros/f1tenth_racetracks/Budapest/Budapest_map'\n",
    "map_path = '/home/praneeth/f1tenth_gym_ros/f1tenth_racetracks/Melbourne/Melbourne_map'\n",
    "map_path = '/home/praneeth/f1tenth_gym_ros/f1tenth_racetracks/Zandvoort/Zandvoort_map'\n",
    "map_ext = '.png'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make('f110_gym:f110-v0', map=map_path, map_ext=map_ext, num_agents=1, timestep=0.01, integrator=Integrator.RK4)\n",
    "env.add_render_callback(render_callback)\n",
    "sx,sy,stheta=0.,0.,1.3\n",
    "obs, step_reward, done, info = env.reset(np.array([[sx,sy,stheta]]))\n",
    "# env.step(np.array([[0.5,0.5]]))\n",
    "env.render(mode='human')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def downsample_input(vector):\n",
    "        segment_length = len(vector) // network_size\n",
    "        reshaped_vector = vector[:segment_length * network_size].reshape(network_size, segment_length)\n",
    "        reduced_vector = np.mean(reshaped_vector, axis=1)\n",
    "        return reduced_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs['scans'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(1,2)\n",
    "ax[0].plot(obs['scans'][0])\n",
    "ax[1].plot(downsample_input(obs['scans'][0]))\n",
    "ax[0].set(title='Original Scan')\n",
    "ax[1].set(title='Downsampled Scan')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lidar_to_binary_features(lidar_data, n_features=10, n_sectors=36, threshold_percentile=60):\n",
    "    \"\"\"\n",
    "    Convert high-dimensional LiDAR data to binary features while preserving similarity.\n",
    "    Similar inputs will produce the same sparse representation.\n",
    "    \n",
    "    Args:\n",
    "        lidar_data (np.array): Input LiDAR readings of size 1080\n",
    "        n_features (int): Size of output binary vector (default: 10)\n",
    "        n_sectors (int): Number of sectors to divide the scan into (default: 36)\n",
    "        threshold_percentile (float): Percentile for binary threshold (default: 70)\n",
    "    \n",
    "    Returns:\n",
    "        np.array: Binary feature vector of size n_features\n",
    "    \n",
    "    Example:\n",
    "        lidar_readings = np.random.rand(1080)  # Your LiDAR data\n",
    "        binary_features = lidar_to_binary_features(lidar_readings)\n",
    "    \"\"\"\n",
    "    # Ensure input is numpy array\n",
    "    lidar_data = np.asarray(lidar_data, dtype=np.float32)\n",
    "    \n",
    "    # 1. Downsample to n_sectors using average pooling\n",
    "    sector_size = len(lidar_data) // n_sectors\n",
    "    sectors = lidar_data[:sector_size * n_sectors].reshape(-1, sector_size)\n",
    "    sector_values = np.mean(sectors, axis=1)\n",
    "    \n",
    "    # 2. Calculate sector differences (gradient-like features)\n",
    "    sector_diffs = np.diff(sector_values, append=sector_values[0])\n",
    "    \n",
    "    # 3. Combine absolute values and differences\n",
    "    combined_features = np.concatenate([\n",
    "        sector_values / np.max(sector_values),  # Normalized values\n",
    "        (sector_diffs - np.min(sector_diffs)) / (np.max(sector_diffs) - np.min(sector_diffs))  # Normalized diffs\n",
    "    ])\n",
    "    \n",
    "    # 4. Project to lower dimension using random projections\n",
    "    # Use fixed random seed for consistency\n",
    "    rng = np.random.RandomState(42)\n",
    "    projection_matrix = rng.normal(0, 1, (len(combined_features), n_features))\n",
    "    projected = np.dot(combined_features, projection_matrix)\n",
    "    \n",
    "    # 5. Apply threshold to create binary features\n",
    "    threshold = np.percentile(projected, threshold_percentile)\n",
    "    binary_features = (projected > threshold).astype(np.int8)\n",
    "    \n",
    "    return binary_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bin = lidar_to_binary_features(obs['scans'][0])\n",
    "bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_scan = np.random.rand(1080)\n",
    "similar_scan = base_scan + np.random.normal(0.1, 0.2, size=1080) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_scan,similar_scan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lidar_to_binary_features(base_scan).shape,lidar_to_binary_features(similar_scan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.linspace(-270//2, 270/2, 51)[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import deque\n",
    "\n",
    "class LiDARRewardCalculator:\n",
    "    def __init__(self, history_size=10, min_speed=0.8, max_speed=2):\n",
    "        self.min_safe_distance = 0.15    # Minimum safe distance from obstacles\n",
    "        self.optimal_distance = 1.1     # Optimal distance from walls for racing line\n",
    "        self.history_size = history_size\n",
    "        self.min_speed = min_speed\n",
    "        self.max_speed = max_speed\n",
    "        \n",
    "        # Initialize history buffers\n",
    "        self.position_history = deque(maxlen=history_size)\n",
    "        self.previous_lidar = None\n",
    "        self.previous_min_distance = None\n",
    "        \n",
    "    def calculate_reward(self, lidar_data, current_speed, collision=False):\n",
    "        if collision:\n",
    "            return -20.0, {'collision_penalty': -20.0}\n",
    "        \n",
    "        # Initialize reward components\n",
    "        rewards = {}\n",
    "        \n",
    "        # 1. Safety reward based on minimum distance to obstacles\n",
    "        min_distance = np.min(lidar_data)\n",
    "        safety_reward = self._calculate_safety_reward(lidar_data)\n",
    "        rewards['safety'] = safety_reward\n",
    "        \n",
    "        # 2. Progress reward based on LiDAR changes and speed\n",
    "        progress_reward = self._calculate_progress_reward(lidar_data, current_speed)\n",
    "        rewards['progress'] = progress_reward\n",
    "        \n",
    "        # 3. Centering reward for keeping optimal distance from walls\n",
    "        centering_reward = self._calculate_centering_reward(lidar_data)\n",
    "        rewards['centering'] = centering_reward\n",
    "        \n",
    "        # 4. Speed reward with safety consideration\n",
    "        # speed_reward = self._calculate_speed_reward(current_speed, min_distance)\n",
    "        # rewards['speed'] = speed_reward\n",
    "        \n",
    "        # # 5. Smoothness reward based on consecutive readings\n",
    "        # smoothness_reward = self._calculate_smoothness_reward(lidar_data)\n",
    "        # rewards['smoothness'] = smoothness_reward\n",
    "        \n",
    "        # Combine rewards with adjusted weights\n",
    "        total_reward = (\n",
    "            0.5 * safety_reward +      # Increased weight for safety\n",
    "            0.25 * progress_reward +   # Progress is still important\n",
    "            0.25 * centering_reward    # Centering for a good racing line\n",
    "            # 0.25 * speed_reward +      # Speed with safety consideration\n",
    "            # 0.1 * smoothness_reward    # Smooth driving\n",
    "        )\n",
    "        \n",
    "        # Update state for next calculation\n",
    "        self.previous_lidar = lidar_data.copy()\n",
    "        self.previous_min_distance = min_distance\n",
    "        \n",
    "        return total_reward, rewards\n",
    "    \n",
    "    def _calculate_safety_reward( self,lidar):\n",
    "        \"\"\"Reward for maintaining a safe distance from obstacles.\"\"\"       \n",
    "        left_min = np.min(lidar[:,:int(lidar.shape[1]*0.3)])\n",
    "        center_min = np.min(lidar[:,int(lidar.shape[1]*0.3):-int(lidar.shape[1]*0.3)])\n",
    "        right_min = np.min(lidar[:,-int(0.3*lidar.shape[1]):])\n",
    "\n",
    "        if left_min < self.min_safe_distance or right_min <self.min_safe_distance :\n",
    "            # Penalty for unsafe distances\n",
    "            return -10.0 * np.exp(-np.mean([left_min,right_min,center_min]))\n",
    "        \n",
    "        elif center_min < self.min_safe_distance:\n",
    "             return -1 * np.exp(-center_min)\n",
    "        \n",
    "        elif left_min < self.min_safe_distance and center_min < self.min_safe_distance:\n",
    "             return -10.0 * np.exp(- np.mean([left_min,center_min]))\n",
    "        \n",
    "        elif right_min <self.min_safe_distance and center_min<self.min_safe_distance:\n",
    "             return -10.0 * np.exp(- np.mean([right_min,center_min]))\n",
    "        else:\n",
    "            # Reward for safe distances, maximized near optimal distance\n",
    "            return 10.0 * np.exp(- np.mean([left_min,right_min,center_min]))\n",
    "    \n",
    "    def _calculate_progress_reward(self, lidar_data, current_speed):\n",
    "        \"\"\"Reward for making progress along the track.\"\"\"\n",
    "        if self.previous_lidar is None:\n",
    "            return 0.0\n",
    "        \n",
    "        # Calculate difference in consecutive LiDAR scans\n",
    "        lidar_diff = np.mean(np.abs(lidar_data - self.previous_lidar))\n",
    "        \n",
    "        # Scale by speed and ensure we're actually moving\n",
    "        progress = lidar_diff * np.clip(current_speed, self.min_speed, self.max_speed)\n",
    "        \n",
    "        # Normalize and cap progress reward\n",
    "        return 5.0 * np.clip(progress, 0, 1)\n",
    "    \n",
    "    def _calculate_centering_reward(self, lidar_data):\n",
    "        \"\"\"Reward for maintaining optimal distance from walls.\"\"\"\n",
    "        left_distances = lidar_data[:,:lidar_data.shape[1]//2]\n",
    "        right_distances = lidar_data[:,lidar_data.shape[1]//2:]\n",
    "        \n",
    "        left_min = np.min(left_distances)\n",
    "        right_min = np.min(right_distances)\n",
    "        \n",
    "        centering_error = abs(left_min - right_min)\n",
    "        \n",
    "        return 5.0 * np.exp(-centering_error / self.optimal_distance)\n",
    "    \n",
    "    # def _calculate_speed_reward(self, current_speed, min_distance):\n",
    "    #     \"\"\"Reward for maintaining high speed while considering safety.\"\"\"\n",
    "    #     if min_distance < self.min_safe_distance:\n",
    "    #         return -5.0  # Penalty for high speed near obstacles\n",
    "            \n",
    "    #     safe_speed_factor = np.clip(min_distance / self.optimal_distance, 0, 1)\n",
    "    #     normalized_speed = np.clip(current_speed / self.max_speed, 0, 1)\n",
    "        \n",
    "    #     return 4.0 * normalized_speed * safe_speed_factor\n",
    "    \n",
    "    # def _calculate_smoothness_reward(self, lidar_data):\n",
    "    #     \"\"\"Reward for smooth driving.\"\"\"\n",
    "    #     if self.previous_lidar is None:\n",
    "    #         return 0.0\n",
    "            \n",
    "    #     movement_diff = np.diff(lidar_data - self.previous_lidar)\n",
    "    #     smoothness = np.mean(np.abs(movement_diff))\n",
    "        \n",
    "    #     return 2.0 * np.exp(-smoothness)\n",
    "    \n",
    "    def reset(self):\n",
    "        \"\"\"Reset internal state between episodes.\"\"\"\n",
    "        self.position_history.clear()\n",
    "        self.previous_lidar = None\n",
    "        self.previous_min_distance = None\n",
    "\n",
    "# Test function to evaluate scenarios\n",
    "def test_reward_scenarios():\n",
    "    reward_calc = LiDARRewardCalculator()\n",
    "    \n",
    "    def generate_scenario(base_distance, noise=0.2):\n",
    "        return np.random.normal(base_distance, noise, 1080).reshape(1,-1)\n",
    "    \n",
    "    safe_scenario = generate_scenario(0.8)\n",
    "    unsafe_scenario = generate_scenario(0.5)\n",
    "    collision_scenario = generate_scenario(0)\n",
    "    \n",
    "    scenarios = {\n",
    "        \"Safe\": (safe_scenario, 1.0, False),\n",
    "        \"Unsafe\": (unsafe_scenario, 0.8, False),\n",
    "        \"Collision\": (collision_scenario, 1.0, True)\n",
    "    }\n",
    "    \n",
    "    for name, (scenario, speed, collision) in scenarios.items():\n",
    "        reward, components = reward_calc.calculate_reward(scenario, speed, collision)\n",
    "        print(f\"\\n{name} Scenario:\")\n",
    "        print(f\"Total Reward: {reward:.2f}\")\n",
    "        print(\"Component Rewards:\")\n",
    "        for component, value in components.items():\n",
    "            print(f\"  {component}: {value:.2f}\")\n",
    "            \n",
    "# Run the test\n",
    "test_reward_scenarios()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_safety_reward( lidar,min_safe_distance=0.1):\n",
    "        \"\"\"Reward for maintaining a safe distance from obstacles.\"\"\"\n",
    "        left = lidar[:,:int(lidar.shape[1]*0.3)]\n",
    "        center = lidar[:,int(lidar.shape[1]*0.3):-int(lidar.shape[1]*0.3)]\n",
    "        right = lidar[:,-int(0.3*lidar.shape[1]):]\n",
    "        \n",
    "        left_min = np.min(left)\n",
    "        center_min = np.min(center)\n",
    "        right_min = np.min(right)\n",
    "\n",
    "        if left_min < min_safe_distance or right_min <min_safe_distance :\n",
    "            # Penalty for unsafe distances\n",
    "            return -10.0 * np.exp(-np.mean([left_min,right_min,center_min]))\n",
    "        \n",
    "        elif center_min < min_safe_distance:\n",
    "             return -1 * np.exp(-center_min)\n",
    "        \n",
    "        elif left_min < min_safe_distance and center_min < min_safe_distance:\n",
    "             return -10.0 * np.exp(- np.mean([left_min,center_min]))\n",
    "        \n",
    "        elif right_min <min_safe_distance and center_min<min_safe_distance:\n",
    "             return -10.0 * np.exp(- np.mean([right_min,center_min]))\n",
    "        else:\n",
    "            # Reward for safe distances, maximized near optimal distance\n",
    "            return 10.0 * np.exp(- np.mean([left_min,right_min,center_min]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_progress_reward(lidar_data, current_speed,previous_lidar):\n",
    "        \"\"\"Reward for making progress along the track.\"\"\"\n",
    "        if previous_lidar is None:\n",
    "            return 0.0\n",
    "        \n",
    "        # Calculate difference in consecutive LiDAR scans\n",
    "        lidar_diff = np.mean(np.abs(lidar_data - previous_lidar))\n",
    "        \n",
    "        # Scale by speed and ensure we're actually moving\n",
    "        progress = lidar_diff * np.clip(current_speed, 0.8, 2)\n",
    "        \n",
    "        # Normalize and cap progress reward\n",
    "        return 5.0 * np.clip(progress, 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_centering_reward( lidar_data,optimal_distance=1.0):\n",
    "        \"\"\"Reward for maintaining optimal distance from walls.\"\"\"\n",
    "        left_distances = lidar_data[:,:lidar_data.shape[1]//2]\n",
    "        right_distances = lidar_data[:,lidar_data.shape[1]//2:]\n",
    "\n",
    "        print(left_distances,right_distances)\n",
    "        \n",
    "        left_min = np.min(left_distances)\n",
    "        right_min = np.min(right_distances)\n",
    "        \n",
    "        centering_error = abs(left_min - right_min)\n",
    "        \n",
    "        return 5.0 * np.exp(-centering_error / optimal_distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lidar = abs(np.random.uniform(0,2,(1,10)))\n",
    "lidar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lidar.shape, lidar[:,:int(lidar.shape[1]*0.3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mi = np.min(lidar)\n",
    "calculate_safety_reward(lidar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_lidar = abs(np.random.uniform(0,2,(1,10)))\n",
    "new_lidar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_l = lidar + np.random.normal(0.,0.05)\n",
    "n_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_progress_reward(lidar,1,n_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_centering_reward(new_lidar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.         -3.          1.85714286]\n",
      " [ 3.         -0.71428571  1.28571429]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "def normalize_weights(weights, new_min=-3, new_max=3):\n",
    "    # Convert to numpy array if not already\n",
    "    weights = np.array(weights)\n",
    "    \n",
    "    # Find the current min and max\n",
    "    current_min = np.min(weights)\n",
    "    current_max = np.max(weights)\n",
    "    \n",
    "    # Normalize to new range\n",
    "    scaled = (weights - current_min) / (current_max - current_min) * (new_max - new_min) + new_min\n",
    "    \n",
    "    return scaled\n",
    "\n",
    "# Example usage\n",
    "weights = [\n",
    "    [0.2, -1.2, 0.5],\n",
    "    [0.9, -0.4, 0.3]\n",
    "]\n",
    "\n",
    "normalized_weights = normalize_weights(weights)\n",
    "print(normalized_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Virtual_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
